{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from common.data import load_data\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOL_CAPACITY = 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"../data/5. Battery Data Set/1. BatteryAgingARC-FY08Q4\")\n",
    "\n",
    "def make_paths(names: Iterable[str]):\n",
    "    return [\n",
    "        base_path.joinpath(name)\n",
    "        for name in names\n",
    "    ]\n",
    "\n",
    "train_paths = make_paths([\"B0005.mat\", \"B0006.mat\"])\n",
    "valid_paths = make_paths([\"B0007.mat\"])\n",
    "test_paths = make_paths([\"B0018.mat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_paths(paths: Iterable[Path]) -> pd.DataFrame:\n",
    "    data = pd.concat({Path(p).stem: load_data(p, \"discharge\") for p in paths})\n",
    "    data.index.names = [\"file\", \"index\"]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_paths(train_paths)\n",
    "valid_data = load_paths(valid_paths)\n",
    "test_data = load_paths(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_dataframe(df: pd.DataFrame, size: int) -> pd.DataFrame:\n",
    "    windows = []\n",
    "    for s in range(size):\n",
    "        shifted = df.shift(s)\n",
    "        shifted.columns = shifted.columns.map(lambda c: f\"{c}_b{s}\")\n",
    "        windows.append(shifted)\n",
    "    return pd.concat(windows, axis=1)\n",
    "\n",
    "def process_label(series: pd.Series, rolling_size: int) -> pd.Series:\n",
    "    res = series.rolling(rolling_size).mean()\n",
    "    res = res.shift(-1)\n",
    "    return res\n",
    "\n",
    "def process_data(data: pd.DataFrame, window_size: int, rolling_size=1):\n",
    "    X = []\n",
    "    y = []\n",
    "    etc = []\n",
    "\n",
    "    for _, group_df in data.groupby(\"file\"):\n",
    "        operation_df = group_df.groupby(\"operation_id\").agg({\n",
    "            \"Time\": [\"max\"],\n",
    "            \"Capacity\": [\"first\"],\n",
    "        })\n",
    "        operation_df.columns = operation_df.columns.map(lambda c: \"_\".join(c))\n",
    "\n",
    "        capacity_change = process_label(operation_df[\"Capacity_first\"], rolling_size)\n",
    "        time_change = process_label(operation_df[\"Time_max\"], rolling_size)\n",
    "\n",
    "        is_alive = operation_df[\"Capacity_first\"] > EOL_CAPACITY\n",
    "        alive_cycles = is_alive.sum()\n",
    "        rul_cycles = -(np.arange(len(is_alive)) - alive_cycles)\n",
    "\n",
    "        data_slice = slice(max(rolling_size, window_size) -1, -1)\n",
    "        X_win = window_dataframe(operation_df, window_size).iloc[data_slice]\n",
    "        \n",
    "        X.append(X_win)\n",
    "        y.append(pd.DataFrame({\n",
    "            \"time\": time_change.iloc[data_slice],\n",
    "            \"cap\": capacity_change.iloc[data_slice],\n",
    "            \"rul\": rul_cycles[data_slice],\n",
    "        }))\n",
    "        etc.append(pd.DataFrame({\n",
    "            \"rul\": rul_cycles[data_slice],\n",
    "            \"real_cap\": operation_df[\"Capacity_first\"].iloc[data_slice],\n",
    "        }))\n",
    "\n",
    "    X = pd.concat(X, ignore_index=True)\n",
    "    y = pd.concat(y, ignore_index=True)\n",
    "    etc = pd.concat(etc, ignore_index=True)\n",
    "\n",
    "    return X, y, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "train_X, train_y, train_etc = process_data(train_data, window_size=window_size)\n",
    "valid_X, valid_y, valid_etc = process_data(valid_data, window_size=window_size)\n",
    "test_X, test_y, test_etc = process_data(test_data, window_size=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = StandardScaler().fit(train_X)\n",
    "train_X_norm = norm.transform(train_X)\n",
    "valid_X_norm = norm.transform(valid_X)\n",
    "test_X_norm = norm.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    target: LGBMRegressor(verbose=-1).fit(\n",
    "        train_X_norm, train_y[target],\n",
    "        eval_set=(valid_X_norm, valid_y[target])\n",
    "    )\n",
    "    for target in train_y.columns\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(y, pred):\n",
    "    plt.scatter(pred, y, alpha=0.2)\n",
    "    plot_min = min(plt.xlim()[0], plt.ylim()[0])\n",
    "    plot_max = max(plt.xlim()[1], plt.ylim()[1])\n",
    "    plt.plot(\n",
    "        [plot_min, plot_max], [plot_min, plot_max], \n",
    "        color=\"orange\", \n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "    plt.title(\"Prediction vs Real\")\n",
    "    plt.xlabel(\"Predictions\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def regression_report(model, X, y):\n",
    "    pred = model.predict(X)\n",
    "\n",
    "    print(f\"rmse: {mean_squared_error(y, pred):0.4f}\")\n",
    "    plot_prediction(y, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, model in models.items():\n",
    "    print(target)\n",
    "    regression_report(model, train_X_norm, train_y[target]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, model in models.items():\n",
    "    print(target)\n",
    "    regression_report(model, valid_X_norm, valid_y[target]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, model in models.items():\n",
    "    print(target)\n",
    "    regression_report(model, test_X_norm, test_y[target]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(models, norm, X: pd.DataFrame, life_window: int):\n",
    "    curr_X = X\n",
    "    for _ in range(life_window):\n",
    "        X_norm = norm.transform(curr_X)\n",
    "        preds = [\n",
    "            model.predict(X_norm)\n",
    "            for _, model in models.items()\n",
    "        ]\n",
    "        new_values = np.column_stack(preds) \n",
    "        new_features = np.column_stack((new_values, curr_X.iloc[:, :-2].values))\n",
    "        curr_X = pd.DataFrame(new_features, columns=X.columns)\n",
    "\n",
    "    return curr_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_simulation_as_classification(models, norm, X, etc, life_window):\n",
    "    sim_res = run_simulation(models, norm, X, 30)\n",
    "    dead_sim = sim_res[\"Capacity_first_b0\"] < EOL_CAPACITY\n",
    "    dead_rul = etc[\"rul\"] < life_window\n",
    "    print(classification_report(dead_rul, dead_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_models = {target: models[target] for target in [\"time\", \"cap\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for life in [30, 50, 70]:\n",
    "    print(f\"Life Window: {life}\")\n",
    "    evaluate_simulation_as_classification(sim_models, norm, train_X, train_etc, life)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for life in [30, 50, 70]:\n",
    "    print(f\"Life Window: {life}\")\n",
    "    evaluate_simulation_as_classification(sim_models, norm, valid_X, valid_etc, life)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for life in [30, 50, 70]:\n",
    "    print(f\"Life Window: {life}\")\n",
    "    evaluate_simulation_as_classification(sim_models, norm, test_X, test_etc, life)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_simulation_as_regression(models, norm, X, etc):\n",
    "    max_rul = etc[\"rul\"].max()\n",
    "    pred_rul = np.full_like(etc[\"rul\"], np.inf, dtype=np.float64)\n",
    "    pred_rul[X[\"Capacity_first_b0\"] < EOL_CAPACITY] = -np.inf\n",
    "    curr_X = X\n",
    "    for i in range(max_rul):\n",
    "        sim_res = run_simulation(models, norm, curr_X, 1)\n",
    "        dead = sim_res[\"Capacity_first_b0\"] < EOL_CAPACITY\n",
    "        pred_rul[dead] = np.minimum(pred_rul[dead], np.full_like(pred_rul[dead], i))\n",
    "        curr_X = sim_res\n",
    "\n",
    "    return pred_rul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_rul = evaluate_simulation_as_regression(sim_models, norm, train_X, train_etc)\n",
    "plot_prediction(train_etc[\"rul\"], train_pred_rul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pred_rul = evaluate_simulation_as_regression(sim_models, norm, valid_X, valid_etc)\n",
    "plot_prediction(valid_etc[\"rul\"], valid_pred_rul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_rul = evaluate_simulation_as_regression(sim_models, norm, test_X, test_etc)\n",
    "plot_prediction(test_etc[\"rul\"], test_pred_rul)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
